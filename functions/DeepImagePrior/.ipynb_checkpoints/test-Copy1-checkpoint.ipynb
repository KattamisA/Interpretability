{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "from models import *\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from skimage.measure import compare_psnr\n",
    "from utils.denoising_utils import *\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "#dtype = torch.cuda.FloatTensor\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "imsize =-1\n",
    "PLOT = True\n",
    "sigma = 25\n",
    "sigma_ = sigma/255.\n",
    "reg_noise_std = 1/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIP_CLASS():\n",
    "    def __init__(self, inp):\n",
    "        self.adv_2 =self.DIP(inp))\n",
    "        return\n",
    "    \n",
    "    def return(self):\n",
    "        return self.adv2\n",
    "\n",
    "    def DIP(img_torch, arch = 'default', LR = 0.01, num_iter = 1000, exp_weight = 0.99, reg_noise_std = 1/30, INPUT = 'noise'):\n",
    "\n",
    "        img_np = torch_to_np(img_torch)\n",
    "\n",
    "        pad = 'reflection'\n",
    "        OPT_OVER = 'net' # 'net,input'\n",
    "        OPTIMIZER='adam' # 'LBFGS'\n",
    "\n",
    "        show_every = 100\n",
    "\n",
    "        if arch == 'default':\n",
    "            input_depth = 3\n",
    "            figsize = 5 \n",
    "            net = skip(\n",
    "                    input_depth, 3, \n",
    "                    num_channels_down = [8, 16, 32],#, 64, 128], \n",
    "                    num_channels_up   = [8, 16, 32],# 64, 128],\n",
    "                    num_channels_skip = [0, 0, 0],# 4, 4], \n",
    "                    upsample_mode='bilinear',\n",
    "                    need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
    "\n",
    "        elif arch == 'complex':\n",
    "            input_depth = 32 \n",
    "            figsize = 4 \n",
    "            net = get_net(input_depth, 'skip', pad,\n",
    "                      skip_n33d=16, \n",
    "                      skip_n33u=16, \n",
    "                      skip_n11=4, \n",
    "                      num_scales=3,\n",
    "                      upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        self.net_input = get_noise(input_depth, INPUT, (img_np.shape[1], img_np.shape[2])).type(dtype).detach()\n",
    "\n",
    "        # Compute number of parameters\n",
    "        s  = sum([np.prod(list(p.size())) for p in net.parameters()]); \n",
    "        print ('Number of params: %d' % s)\n",
    "\n",
    "        # Loss\n",
    "        mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "        #####\n",
    "        self.net_input_saved = net_input.detach().clone()\n",
    "        self.noise = net_input.detach().clone()\n",
    "        self.out_avg = None\n",
    "        self.last_net = None\n",
    "        self.psrn_noisy_last = 0\n",
    "\n",
    "        self.i = 0\n",
    "\n",
    "        def closure(,):\n",
    "\n",
    "            #global i, out_avg, psrn_noisy_last, last_net, net_input, reg_noise_std\n",
    "    \n",
    "            if self.reg_noise_std > 0:\n",
    "                    self.net_input = self.net_input_saved + (self.noise.normal_() * self.reg_noise_std)\n",
    "\n",
    "            self.out = self.net(net_input)\n",
    "\n",
    "            # Smoothing\n",
    "            if self.out_avg is None:\n",
    "                self.out_avg = self.out.detach()\n",
    "            else:\n",
    "                self.out_avg = self.out_avg * exp_weight + out.detach() * (1 - exp_weight)\n",
    "\n",
    "            total_loss = mse(out, img_torch)\n",
    "            total_loss.backward()\n",
    "\n",
    "            psrn_noisy = compare_psnr(img_np, out.detach().cpu().numpy()[0]) \n",
    "\n",
    "                # Note that we do not have GT for the \"snail\" example\n",
    "                # So 'PSRN_gt', 'PSNR_gt_sm' make no sense\n",
    "            print ('DIP Iteration %05d    Loss %f   PSNR_noisy: %f ' % (i, total_loss.item(), psrn_noisy), '\\r', end='')\n",
    "            if  PLOT and i % show_every == 0:\n",
    "                out_np = torch_to_np(out)\n",
    "                plot_image_grid([np.clip(out_np, 0, 1), \n",
    "                                 np.clip(torch_to_np(out_avg), 0, 1)], factor=figsize, nrow=2)        \n",
    "            # Backtracking\n",
    "            if i % show_every:\n",
    "                if psrn_noisy - psrn_noisy_last < -5: \n",
    "                    print('Falling back to previous checkpoint.')\n",
    "                    for new_param, net_param in zip(last_net, net.parameters()):\n",
    "                        net_param.detach().copy_(new_param)\n",
    "\n",
    "                    return total_loss*0\n",
    "                else:\n",
    "                    last_net = [x.detach().cpu() for x in net.parameters()]\n",
    "                    psrn_noisy_last = psrn_noisy          \n",
    "            i += 1\n",
    "\n",
    "            return total_loss\n",
    "\n",
    "        out = net(net_input)    \n",
    "        p = get_params(OPT_OVER, net, net_input)\n",
    "        optimize(OPTIMIZER, p, closure, LR, num_iter)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "inp = torch.ones(1,3,224,224)\n",
    "inp_np = torch_to_np(inp)\n",
    "img_np = inp_npprint(inp_np.shape)\n",
    "adv_2 = DIP_CLASS(imp)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
