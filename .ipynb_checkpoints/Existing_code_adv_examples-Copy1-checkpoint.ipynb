{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import torch\nfrom torch.autograd import Variable\nfrom torchvision import models\nimport torch.nn as nn\nfrom torchvision import transforms\n\nimport numpy as np\nimport cv2\nimport argparse\nfrom imagenet_classes import classes\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--img', type=str, default='images/goldfish.jpg', help='path to image')\nparser.add_argument('--model', type=str, default='resnet18',\n\t\t\t\t\t choices=['resnet18', 'inception_v3', 'resnet50'],\n\t\t\t\t\t required=False, help=\"Which network?\")\nparser.add_argument('--y', type=int, required=False, help='Label')\n\nargs = parser.parse_args()\nimage_path = args.img\nmodel_name = args.model\ny_true = args.y\n\nprint('Fast Gradient Sign Method')\nprint('Model: %s' %(model_name))\nprint()\n\ndef nothing(x):\n\tpass\n\nwindow_adv = 'adversarial image'\ncv2.namedWindow(window_adv)\ncv2.createTrackbar('eps', window_adv, 1, 255, nothing)\n\n# load image and reshape to (3, 224, 224) and RGB (not BGR)\n# preprocess as described here: http://pytorch.org/docs/master/torchvision/models.html\norig = cv2.imread(image_path)[..., ::-1]\norig = cv2.resize(orig, (224, 224))\nimg = orig.copy().astype(np.float32)\nperturbation = np.empty_like(orig)\n\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\nimg /= 255.0\nimg = (img - mean)/std\nimg = img.transpose(2, 0, 1)\n\n# load model\nmodel = getattr(models, model_name)(pretrained=True)\nmodel.eval().cuda()\ncriterion = nn.CrossEntropyLoss().cuda()\n\n# prediction before attack\ninp = Variable(torch.from_numpy(img).cuda().float().unsqueeze(0), requires_grad=True)\nout = model(inp)\npred = np.argmax(out.data.cpu().numpy())\nprint('Prediction before attack: %s' %(classes[pred].split(',')[0]))\n\nwhile True:\n\t# get trackbar position\n\teps = cv2.getTrackbarPos('eps', window_adv)\n\tinp = Variable(torch.from_numpy(img).cuda().float().unsqueeze(0), requires_grad=True)\n\t\n\t# compute loss\n\tout = model(inp)\n\tloss = criterion(out, Variable(torch.Tensor([float(pred)]).cuda().long()))\n\t\n\t# compute gradients\n\tloss.backward()\n\t\n\t# this is it, this is the method\n\tinp.data = inp.data + ((eps/255.0) * torch.sign(inp.grad.data))\n\t\n\tinp.grad.data.zero_() # this is just a compulsion, unnecessary here\n\n\t# predict on the adversarial image\n\tpred_adv = np.argmax(model(inp).data.cpu().numpy())\n\tprint(\" \"*60, end='\\r') # to clear previous line, not an elegant way\n\tprint(\"After attack: eps [%f] \\t%s\"\n\t\t\t%(eps, classes[pred_adv].split(',')[0]), end=\"\\r\")#, end='\\r')#'eps:', eps, end='\\r')\n\t\n\t# deprocess image\n\tadv = inp.data.cpu().numpy()[0]\n\tperturbation = (adv-img).transpose(1,2,0)#cv2.normalize((adv - img).transpose(1, 2, 0), perturbation, 0, 255, cv2.NORM_MINMAX, 0)\n\tadv = adv.transpose(1, 2, 0)\n\tadv = (adv * std) + mean\n\tadv = adv * 255.0\n\tadv = adv[..., ::-1] # RGB to BGR\n\tadv = np.clip(adv, 0, 255).astype(np.uint8)\t\n\t\n\tcv2.imshow(window_adv, perturbation)\n\tcv2.imshow('perturbation', adv)\n\tkey = cv2.waitKey(500) & 0xFF\n\tif key == 27:\n\t\tbreak\n\telif key == ord('s'):\n\t\tcv2.imwrite('img_adv.png', adv)\n\t\tcv2.imwrite('perturbation.png', perturbation)\nprint()\ncv2.destroyAllWindows()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}