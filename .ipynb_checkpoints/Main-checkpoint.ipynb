{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.adversarial import *\n",
    "from functions.dip import *\n",
    "from functions.classification import *\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from functions.utils import *\n",
    "from functions.saliency import *\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.device_count() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the trial number is: 0\n",
      "the trial number is: 1\n",
      "the trial number is: 2\n",
      "the trial number is: 3\n",
      "the trial number is: 4\n",
      "the trial number is: 5\n",
      "the trial number is: 6\n",
      "the trial number is: 7\n",
      "the trial number is: 8\n",
      "the trial number is: 9\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-006abc43dd70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#generate_saliency_maps('results/Adv_DIP/Multiple_images/panda', img, 10001)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgenerate_saliency_maps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\University of Cambridge - Engineering\\Engineering IIB\\4th year project\\VI. Code\\Interpretability\\functions\\saliency.py\u001b[0m in \u001b[0;36mgenerate_saliency_maps\u001b[1;34m(path, img_path, model_type, cuda)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     output_img = generate_entrie_images(img, img_gradient, img_gradient_overlay, img_integrated_gradient,\n\u001b[1;32m---> 58\u001b[1;33m                                         img_integrated_gradient_overlay)\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;31m#cv2.imwrite(path + '/test', np.uint8(output_img))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/test.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\University of Cambridge - Engineering\\Engineering IIB\\4th year project\\VI. Code\\Interpretability\\functions\\saliency_utils.py\u001b[0m in \u001b[0;36mgenerate_entrie_images\u001b[1;34m(img_origin, img_grad, img_grad_overlay, img_integrad, img_integrad_overlay)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mblank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mblank_hor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimg_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mupper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_origin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_grad_overlay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_grad\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mdown\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_origin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_integrad_overlay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_integrad\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblank_hor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdown\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "images = 'panda.jpg'\n",
    "  \n",
    "#generate_saliency_maps('results/Adv_DIP/Multiple_images/panda', img, 10001)\n",
    "generate_saliency_maps('data', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"data/goldfish.jpg\")\n",
    "print(img.shape)\n",
    "img = img[:, :, (2, 1, 0)]\n",
    "print(img.shape)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['panda.jpg', 'peacock.jpg', 'F16_GT.png', 'monkey.jpg', 'zebra_GT.png', 'goldfish.jpg']\n",
    "for i in images:\n",
    "    orig = cv2.imread(\"data/{}\".format(i))[..., ::-1]\n",
    "    orig = cv2.resize(orig, (224, 224))\n",
    "    img = orig.copy().astype(np.float32)\n",
    "    classification(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_input = get_noise(3, 'noise', (224, 224))\n",
    "print(net_input)\n",
    "print(net_input.shape)\n",
    "net_input_saved = net_input.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "last_net = \n",
    "net_input = global_values.net_input_saved + (global_values.noise.normal_() * global_values.noise_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Gradient Descent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adv1, orig, pert = adversarial_examples('data/goldfish.jpg', method='FGSM',eps=100,show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Iterative Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv2, orig, pert = adversarial_examples('data/goldfish.jpg',method='BI',eps=100,show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Likely Class Iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adv3, orig, pert = adversarial_examples('data/goldfish.jpg',method='LLCI',eps=100,show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16,16))\n",
    "\n",
    "fig.add_subplot(1, 3, 1)\n",
    "plt.title('FGSM')\n",
    "plt.imshow(adv1)\n",
    "\n",
    "fig.add_subplot(1, 3, 2)\n",
    "plt.title('BI')\n",
    "plt.imshow(adv2)\n",
    "\n",
    "fig.add_subplot(1, 3, 3)\n",
    "plt.title('LLCI')\n",
    "plt.imshow(adv3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## Save images\n",
    "plt.imsave(\"results/Goldfish_fgsm_eps100.png\", adv1, format=\"png\")\n",
    "plt.imsave(\"results/Goldfish_bi_eps100.png\", adv2, format=\"png\")\n",
    "plt.imsave(\"results/Goldfish_llci_eps100.png\", adv3, format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Image Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = cv2.imread(\"data/lighthouse.jpg\")[..., ::-1]\n",
    "orig = cv2.resize(orig, (256, 256))\n",
    "img = orig.copy().astype(np.float32)\n",
    "\n",
    "## Save images\n",
    "#plt.imsave(\"results/F16_noisy.png\", np.clip(img_noisy, 0, 1), format=\"png\")\n",
    "#plt.imsave(\"results/F16.png\", np.clip(img, 0, 1), format=\"png\")\n",
    "\n",
    "dip_out = dip(img, num_iter=10001, save=False, plot=False, save_path='results/Adv_DIP/', arch='complex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observing general images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=20\n",
    "orig = cv2.imread(\"results/Adv_DIP/FGSM_eps100/it_{}.png\".format(i*100))[..., ::-1]\n",
    "orig = cv2.resize(orig, (256, 256))\n",
    "img = orig.copy().astype(np.float32)\n",
    "P,R = classification(img)\n",
    "plt.imshow(orig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 150\n",
    "value = 100\n",
    "\n",
    "adv, orig, pert = adversarial_examples('data/goldfish.jpg',model_name = 'resnet18', method='FGSM',eps=value, show=False)\n",
    "adv_noisy = adv + std*np.random.randn(224,224,3)\n",
    "adv_noisy = np.clip(adv_noisy,0,255).astype(np.uint8)\n",
    "plt.imshow(adv_noisy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_300 = cv2.imread(\"results/Adv_DIP/LLCI_eps5/it_{}.png\".format(300))[..., ::-1]\n",
    "it_1200 = cv2.imread(\"results/Adv_DIP/LLCI_eps5/it_{}.png\".format(1200))[..., ::-1]\n",
    "it_2500 = cv2.imread(\"results/Adv_DIP/LLCI_eps5/it_{}.png\".format(5000))[..., ::-1]\n",
    "orig = cv2.imread('data/panda.jpg')[...,::-1]\n",
    "\n",
    "P,R = classification(orig)\n",
    "P,R = classification(it_300)\n",
    "P,R = classification(it_1200)\n",
    "P,R = classification(it_2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find original classification class\n",
    "iterations = 9101\n",
    "#adv, orig, pert = adversarial_examples('data/goldfish.jpg',model_name = 'resnet18', method='LLCI',eps=100, show=False)\n",
    "P, R = classification(orig, model_name = 'resnet18', sort = True, show=False)\n",
    "original_class = R[0,0]\n",
    "P, R = classification(adv, model_name = 'resnet18', sort = True, show=False)\n",
    "final_classes = R[0,0:5]\n",
    "\n",
    "# Create matrix to store values\n",
    "Confidence = np.ones([round((iterations-1)/100+1),6])\n",
    "Ranks_matrix = np.ones([round((iterations-1)/100+1),5])\n",
    "\n",
    "\n",
    "for i in range(round((iterations-1)/100+1)):\n",
    "    orig = cv2.imread(\"results/Adv_DIP/Complex_LLCI_eps5/it_{}.png\".format(i*100))[..., ::-1]\n",
    "    orig = cv2.resize(orig, (256, 256))\n",
    "    img = orig.copy().astype(np.float32)\n",
    "    Probs, Ranks = classification(img, model_name = 'resnet18', sort = False, show = False)\n",
    "    Probs_np = torch_to_np(Probs)\n",
    "    Confidence[i,0] = Probs_np[original_class]\n",
    "    P , Ranking = Probs.sort(descending=True)\n",
    "    Ranking_np = torch_to_np(Ranking)\n",
    "    for j in range(5):\n",
    "        Confidence[i,j+1] = Probs_np[final_classes[j]]\n",
    "        Ranks_matrix[i,j] = Ranking_np[j]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = np.arange(0, iterations+99, 100)\n",
    "iters = round((iterations-1)/100+1)\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.xlabel('DIP Iterations')\n",
    "plt.ylabel('Confidence of true class')\n",
    "plt.plot(it,Confidence)\n",
    "plt.show()\n",
    "\n",
    "# Save stuff\n",
    "fig.savefig('results/Adv_DIP/Simple_LLCI_eps5/Graph_Complex_LLCI_eps100_full.png')\n",
    "np.savetxt('results/Adv_DIP/Simple_LLCI_eps5/Complex_LLCI_eps100_full.txt', Confidence)\n",
    "np.savetxt('results/Adv_DIP/Simple_LLCI_eps5/Complex_LLCI_eps100_ranks.txt', Ranks_matrix)\n",
    "for i in range(5):\n",
    "    print(classes[int(Ranks_matrix[-1,i])].split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "#import argparse\n",
    "import numpy as np\n",
    "from functions.utils import *\n",
    "from functions.adversarial import *\n",
    "from functions.dip import *\n",
    "from functions.classification import *\n",
    "\n",
    "\n",
    "for i in ['panda.jpg']:\n",
    "    adv, orig, pert = adversarial_examples(\"data/{}\".format(i), method = \"FGSM\", eps=1, show=False)\n",
    "    out = dip(adv, num_iter=51, save=True, plot=True, save_path='results/Adv_DIP', arch='simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_common = 'results/Adv_DIP/Architecture_tests/{}'\n",
    "print(save_path_common.format('Adam/test{}'.format(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1,4):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
