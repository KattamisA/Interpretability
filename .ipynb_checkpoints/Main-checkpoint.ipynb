{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.optim\n",
    "from functions.models.optim import *\n",
    "\n",
    "from skimage.measure import compare_psnr\n",
    "from functions.models import *\n",
    "from copy import deepcopy\n",
    "from functions.utils.global_parameters import *\n",
    "from functions.utils.common_utils import torch_to_np\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "#dtype = torch.cuda.FloatTensor\n",
    "dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dip(img_np, arch = 'default', LR = 0.01, num_iter = 1000, reg_noise_std = 1.0/30,exp_weight = 0.99, INPUT = 'noise', save = False, save_path = '', plot = True, input_depth = None, name = None, loss_fn = \"MSE\", OPTIMIZER = \"adam\", pad = 'zero',  OPT_OVER = 'net' ):\n",
    "    \n",
    "    glparam = global_parameters()\n",
    "    glparam.set_params(save, plot, reg_noise_std, exp_weight)\n",
    "    glparam.load_images(img_np)\n",
    "    glparam.img_torch = glparam.img_torch.type(dtype)\n",
    "    \n",
    "    if arch == 'simple':\n",
    "        if input_depth == None:\n",
    "            input_depth = 3 \n",
    "        glparam.net = get_net(input_depth,'skip', pad,\n",
    "                skip_n33d=16, \n",
    "                skip_n33u=16, \n",
    "                skip_n11=0, \n",
    "                num_scales=3,\n",
    "                upsample_mode='bilinear').type(dtype)\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    net_input = get_noise(input_depth, INPUT, (glparam.img_np.shape[1], glparam.img_np.shape[2])).type(dtype).detach()   \n",
    "    glparam.net_input_saved = net_input.detach().clone()\n",
    "    glparam.noise = net_input.detach().clone()\n",
    "    \n",
    "    # Compute number of parameters\n",
    "    param_numbers  = sum([np.prod(list(p.size())) for p in glparam.net.parameters()]) \n",
    "    print ('\\n Number of params: %d' % param_numbers)\n",
    "\n",
    "    # Loss function\n",
    "    if loss_fn == 'MSE':\n",
    "        criterion = torch.nn.MSELoss().type(dtype)\n",
    "    if loss_fn == 'KLDiv':\n",
    "        criterion = torch.nn.KLDivLoss().type(dtype)\n",
    "        \n",
    "    if save == True:\n",
    "        f= open(\"{}/Stats.txt\".format(save_path),\"w+\")\n",
    "        f.write(\"{:>11}{:>12}{:>12}\\n\".format('Iterations','Total_Loss','PSNR'))\n",
    "        save_net_details(save_path, arch, param_numbers, pad, OPT_OVER, OPTIMIZER, input_depth,\n",
    "                 loss_fn = loss_fn, LR = LR, num_iter = num_iter, exp_weight = glparam.exp,\n",
    "                 reg_noise_std = reg_noise_std, INPUT = 'INPUT', net = glparam.net)\n",
    "                \n",
    "    def closure(iter_value):\n",
    "        show_every = 100\n",
    "        figsize = 4\n",
    "        \n",
    "        ## Initialiaze/ Update variables\n",
    "        if glparam.noise_std > 0.0:\n",
    "            net_input = glparam.net_input_saved + (glparam.noise.normal_() * glparam.noise_std)\n",
    "        net_input = torch.tensor(net_input, dtype=torch.float32, requires_grad=True)\n",
    "        out = glparam.net(net_input)#, requires_grad=True)\n",
    "\n",
    "        ## Exponential Smoothing\n",
    "        if glparam.out_avg is None:\n",
    "            glparam.out_avg = out.detach()\n",
    "        else:\n",
    "            glparam.out_avg = glparam.out_avg * glparam.exp + out.detach() * (1 - glparam.exp)\n",
    "        \n",
    "        ## Calculate loss\n",
    "        total_loss = criterion(out, glparam.img_torch)\n",
    "        set_trace()\n",
    "        total_loss.backward()\n",
    "        set_trace()\n",
    "        \n",
    "        glparam.psnr_noisy = compare_psnr(glparam.img_np, out.detach().cpu().numpy()[0]).astype(np.float32)\n",
    "            \n",
    "        print ('DIP Iteration {:>11}   Loss {:>11.7f}   PSNR_noisy: {:>5.4f}'.format(\n",
    "            iter_value, total_loss.item(), glparam.psnr_noisy), end='\\r')\n",
    "        \n",
    "        ## Backtracking   \n",
    "        if (glparam.psnr_noisy_last - glparam.psnr_noisy) > 5.0:\n",
    "            glparam.interrupts = glparam.interrupts + 1\n",
    "            print('\\n Falling back to previous checkpoint.')\n",
    "            glparam.net.load_state_dict(glparam.last_net.state_dict())\n",
    "            glparam.optimizer.load_state_dict(glparam.optimizer_last.state_dict())\n",
    "            \n",
    "            if glparam.interrupts > 3:\n",
    "                glparam.psnr_noisy_last = glparam.psnr_noisy\n",
    "                \n",
    "            if OPTIMIZER == \"adam\":     \n",
    "                for j in range(iter_value % show_every - 1):                \n",
    "                    glparam.optimizer.zero_grad()\n",
    "                    closure(iter_value - (iter_value % show_every) + j + 1)\n",
    "                    glparam.optimizer.step()\n",
    "                glparam.optimizer.zero_grad()\n",
    "                closure(iter_value)          \n",
    "                print('\\n Return back to the original')                        \n",
    "                return total_loss \n",
    "            \n",
    "            if OPTIMIZER == \"EntropySGD\":\n",
    "                for j in range(iter_value % show_every - 1):\n",
    "                    glparam.optimizer.zero_grad()\n",
    "                    glparam.optimizer.step(iter_value - (iter_value % show_every) + j + 1, closure, glparam.net, criterion)\n",
    "                glparam.optimizer.zero_grad()\n",
    "                closure(iter_value)   \n",
    "                print('\\n Return back to the original')                        \n",
    "                return total_loss                      \n",
    "            \n",
    "        if (iter_value % show_every) == 0: \n",
    "            glparam.last_net = deepcopy(glparam.net)\n",
    "            glparam.psnr_noisy_last = glparam.psnr_noisy\n",
    "            glparam.optimizer_last = deepcopy(glparam.optimizer)\n",
    "            \n",
    "            if glparam.interrupts > 3 :\n",
    "                print(\"\\n Error, was not able to converge after reset\")\n",
    "            glparam.interrupts = 0\n",
    "            \n",
    "            if glparam.PLOT:\n",
    "                fig=plt.figure(figsize=(16, 16))\n",
    "                fig.add_subplot(1, 3, 1)\n",
    "                plt.imshow(np.clip(torch_to_np(out), 0, 1).transpose(1, 2, 0))\n",
    "                plt.title('Output')\n",
    "                fig.add_subplot(1, 3, 2)\n",
    "                plt.imshow(np.clip(torch_to_np(glparam.out_avg), 0, 1).transpose(1, 2, 0))\n",
    "                plt.title('Averaged Output')\n",
    "                fig.add_subplot(1, 3, 3)\n",
    "                plt.title('Original/Target')\n",
    "                plt.imshow(glparam.img_np.transpose(1, 2, 0))\n",
    "                plt.show()\n",
    "                \n",
    "            if glparam.save:\n",
    "                f = open(\"{}/Stats.txt\".format(save_path),\"a\")\n",
    "                f.write(\"{:>11}{:>12.8f}{:>12.8f}\\n\".format(iter_value, total_loss.item(), glparam.psnr_noisy))\n",
    "                plt.imsave(\"{}/it_{}.png\".format(save_path,iter_value),\n",
    "                       np.clip(torch_to_np(glparam.out_avg), 0, 1).transpose(1,2,0), format=\"png\")\n",
    "                \n",
    "        return total_loss\n",
    "        \n",
    "    ### Optimize\n",
    "    glparam.net.train()\n",
    "    p = get_params(OPT_OVER, glparam.net, net_input)\n",
    "    \n",
    "    if OPTIMIZER == \"adam\":\n",
    "        glparam.optimizer = torch.optim.Adam(p, lr = LR)\n",
    "        for j in range(num_iter):\n",
    "            glparam.optimizer.zero_grad()\n",
    "            closure(j)\n",
    "            glparam.optimizer.step()            \n",
    "    if OPTIMIZER == \"EntropySGD\":\n",
    "        glparam.optimizer = EntropySGD(p,config=dict(lr = LR))\n",
    "        for j in range(num_iter):\n",
    "            glparam.optimizer.zero_grad()\n",
    "            glparam.optimizer.step(j, closure, glparam.net, criterion)    \n",
    "    print('\\n')       \n",
    "    \n",
    "    out = glparam.net(net_input)\n",
    "    glparam.out_avg = glparam.out_avg * glparam.exp + out.detach() * (1 - glparam.exp)\n",
    "    return glparam.out_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of params: 20355\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'requires_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-032f9b7faecc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/goldfish.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0march\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'simple'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-5c598d98f65b>\u001b[0m in \u001b[0;36mdip\u001b[1;34m(img_np, arch, LR, num_iter, reg_noise_std, exp_weight, INPUT, save, save_path, plot, input_depth, name, loss_fn, OPTIMIZER, pad, OPT_OVER)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mglparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[0mglparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mOPTIMIZER\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"EntropySGD\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5c598d98f65b>\u001b[0m in \u001b[0;36mclosure\u001b[1;34m(iter_value)\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mnet_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet_input_saved\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mglparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mglparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mnet_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m## Exponential Smoothing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'requires_grad'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('data/goldfish.jpg')[..., ::-1]\n",
    "img_np = np.array(img)\n",
    "_, dip(img_np, arch = 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
