{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.optim\n",
    "from functions.models.optim import *\n",
    "\n",
    "from skimage.measure import compare_psnr\n",
    "from functions.models import *\n",
    "from copy import deepcopy\n",
    "from functions.utils.global_parameters import *\n",
    "from functions.utils.common_utils import torch_to_np\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "#dtype = torch.cuda.FloatTensor\n",
    "dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dip(img_np, arch = 'default', LR = 0.01, num_iter = 1000, reg_noise_std = 1.0/30,exp_weight = 0.99, INPUT = 'noise', save = False, save_path = '', plot = True, input_depth = None, name = None, loss_fn = \"MSE\", OPTIMIZER = \"adam\", pad = 'zero',  OPT_OVER = 'net' ):\n",
    "    \n",
    "    glparam = global_parameters()\n",
    "    glparam.set_params(save, plot, reg_noise_std, exp_weight)\n",
    "    glparam.load_images(img_np)\n",
    "    glparam.img_torch = glparam.img_torch.type(dtype)\n",
    "    \n",
    "    if arch == 'simple':\n",
    "        if input_depth == None:\n",
    "            input_depth = 3 \n",
    "        glparam.net = get_net(input_depth,'skip', pad,\n",
    "                skip_n33d=16, \n",
    "                skip_n33u=16, \n",
    "                skip_n11=0, \n",
    "                num_scales=3,\n",
    "                upsample_mode='bilinear').type(dtype)\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    net_input = get_noise(input_depth, INPUT, (glparam.img_np.shape[1], glparam.img_np.shape[2])).type(dtype).detach()   \n",
    "    glparam.net_input_saved = net_input.detach().clone()\n",
    "    glparam.noise = net_input.detach().clone()\n",
    "    \n",
    "    # Compute number of parameters\n",
    "    param_numbers  = sum([np.prod(list(p.size())) for p in glparam.net.parameters()]) \n",
    "    print ('\\n Number of params: %d' % param_numbers)\n",
    "\n",
    "    # Loss function\n",
    "    if loss_fn == 'MSE':\n",
    "        criterion = torch.nn.MSELoss().type(dtype)\n",
    "    if loss_fn == 'KLDiv':\n",
    "        criterion = torch.nn.KLDivLoss().type(dtype)\n",
    "        \n",
    "    if save == True:\n",
    "        f= open(\"{}/Stats.txt\".format(save_path),\"w+\")\n",
    "        f.write(\"{:>11}{:>12}{:>12}\\n\".format('Iterations','Total_Loss','PSNR'))\n",
    "        save_net_details(save_path, arch, param_numbers, pad, OPT_OVER, OPTIMIZER, input_depth,\n",
    "                 loss_fn = loss_fn, LR = LR, num_iter = num_iter, exp_weight = glparam.exp,\n",
    "                 reg_noise_std = reg_noise_std, INPUT = 'INPUT', net = glparam.net)\n",
    "                \n",
    "    def closure(iter_value):\n",
    "        show_every = 100\n",
    "        figsize = 4\n",
    "        \n",
    "        ## Initialiaze/ Update variables\n",
    "        if glparam.noise_std > 0.0:\n",
    "            net_input = glparam.net_input_saved + (glparam.noise.normal_() * glparam.noise_std)\n",
    "        net_input = torch.tensor(net_input, dtype=torch.float32, requires_grad=True)\n",
    "        out = glparam.net(net_input)\n",
    "\n",
    "        ## Exponential Smoothing\n",
    "        if glparam.out_avg is None:\n",
    "            glparam.out_avg = out.detach()\n",
    "        else:\n",
    "            glparam.out_avg = glparam.out_avg * glparam.exp + out.detach() * (1 - glparam.exp)\n",
    "        \n",
    "        ## Calculate loss\n",
    "        total_loss = criterion(out, glparam.img_torch)\n",
    "        total_loss.backward()\n",
    "        set_trace()\n",
    "        \n",
    "        glparam.psnr_noisy = compare_psnr(glparam.img_np, out.detach().cpu().numpy()[0]).astype(np.float32)\n",
    "            \n",
    "        print ('DIP Iteration {:>11}   Loss {:>11.7f}   PSNR_noisy: {:>5.4f}'.format(\n",
    "            iter_value, total_loss.item(), glparam.psnr_noisy), end='\\r')\n",
    "        \n",
    "        ## Backtracking   \n",
    "        if (glparam.psnr_noisy_last - glparam.psnr_noisy) > 5.0:\n",
    "            glparam.interrupts = glparam.interrupts + 1\n",
    "            print('\\n Falling back to previous checkpoint.')\n",
    "            glparam.net.load_state_dict(glparam.last_net.state_dict())\n",
    "            glparam.optimizer.load_state_dict(glparam.optimizer_last.state_dict())\n",
    "            \n",
    "            if glparam.interrupts > 3:\n",
    "                glparam.psnr_noisy_last = glparam.psnr_noisy\n",
    "                \n",
    "            if OPTIMIZER == \"adam\":     \n",
    "                for j in range(iter_value % show_every - 1):                \n",
    "                    glparam.optimizer.zero_grad()\n",
    "                    closure(iter_value - (iter_value % show_every) + j + 1)\n",
    "                    glparam.optimizer.step()\n",
    "                glparam.optimizer.zero_grad()\n",
    "                closure(iter_value)          \n",
    "                print('\\n Return back to the original')                        \n",
    "                return total_loss \n",
    "            \n",
    "            if OPTIMIZER == \"EntropySGD\":\n",
    "                for j in range(iter_value % show_every - 1):\n",
    "                    glparam.optimizer.zero_grad()\n",
    "                    glparam.optimizer.step(iter_value - (iter_value % show_every) + j + 1, closure, glparam.net, criterion)\n",
    "                glparam.optimizer.zero_grad()\n",
    "                closure(iter_value)   \n",
    "                print('\\n Return back to the original')                        \n",
    "                return total_loss                      \n",
    "            \n",
    "        if (iter_value % show_every) == 0: \n",
    "            glparam.last_net = deepcopy(glparam.net)\n",
    "            glparam.psnr_noisy_last = glparam.psnr_noisy\n",
    "            glparam.optimizer_last = deepcopy(glparam.optimizer)\n",
    "            \n",
    "            if glparam.interrupts > 3 :\n",
    "                print(\"\\n Error, was not able to converge after reset\")\n",
    "            glparam.interrupts = 0\n",
    "            \n",
    "            if glparam.PLOT:\n",
    "                fig=plt.figure(figsize=(16, 16))\n",
    "                fig.add_subplot(1, 3, 1)\n",
    "                plt.imshow(np.clip(torch_to_np(out), 0, 1).transpose(1, 2, 0))\n",
    "                plt.title('Output')\n",
    "                fig.add_subplot(1, 3, 2)\n",
    "                plt.imshow(np.clip(torch_to_np(glparam.out_avg), 0, 1).transpose(1, 2, 0))\n",
    "                plt.title('Averaged Output')\n",
    "                fig.add_subplot(1, 3, 3)\n",
    "                plt.title('Original/Target')\n",
    "                plt.imshow(glparam.img_np.transpose(1, 2, 0))\n",
    "                plt.show()\n",
    "                \n",
    "            if glparam.save:\n",
    "                f = open(\"{}/Stats.txt\".format(save_path),\"a\")\n",
    "                f.write(\"{:>11}{:>12.8f}{:>12.8f}\\n\".format(iter_value, total_loss.item(), glparam.psnr_noisy))\n",
    "                plt.imsave(\"{}/it_{}.png\".format(save_path,iter_value),\n",
    "                       np.clip(torch_to_np(glparam.out_avg), 0, 1).transpose(1,2,0), format=\"png\")\n",
    "                \n",
    "        return total_loss\n",
    "        \n",
    "    ### Optimize\n",
    "    glparam.net.train()\n",
    "    p = get_params(OPT_OVER, glparam.net, net_input)\n",
    "    \n",
    "    if OPTIMIZER == \"adam\":\n",
    "        glparam.optimizer = torch.optim.Adam(p, lr = LR)\n",
    "        for j in range(num_iter):\n",
    "            glparam.optimizer.zero_grad()\n",
    "            closure(j)\n",
    "            glparam.optimizer.step()            \n",
    "    if OPTIMIZER == \"EntropySGD\":\n",
    "        glparam.optimizer = EntropySGD(p,config=dict(lr = LR))\n",
    "        for j in range(num_iter):\n",
    "            glparam.optimizer.zero_grad()\n",
    "            glparam.optimizer.step(j, closure, glparam.net, criterion)    \n",
    "    print('\\n')       \n",
    "    \n",
    "    out = glparam.net(net_input)\n",
    "    glparam.out_avg = glparam.out_avg * glparam.exp + out.detach() * (1 - glparam.exp)\n",
    "    return glparam.out_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of params: 20355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-2-f5a0c3771562>(62)closure()\n",
      "     60         set_trace()\n",
      "     61 \n",
      "---> 62         glparam.psnr_noisy = compare_psnr(glparam.img_np, out.detach().cpu().numpy()[0]).astype(np.float32)\n",
      "     63 \n",
      "     64         print ('DIP Iteration {:>11}   Loss {:>11.7f}   PSNR_noisy: {:>5.4f}'.format(\n",
      "\n",
      "ipdb> out.grad\n",
      "ipdb> input.grad\n",
      "*** AttributeError: 'function' object has no attribute 'grad'\n",
      "ipdb> net_input.grad\n",
      "tensor([[[[ 1.7442e-07,  2.6749e-07,  1.6338e-07,  ...,  7.1478e-08,\n",
      "           -1.0701e-07, -2.7952e-07],\n",
      "          [ 1.0810e-07, -6.1325e-08, -4.6639e-08,  ..., -5.8087e-08,\n",
      "            4.3745e-07,  1.5662e-07],\n",
      "          [ 4.6022e-09, -2.3011e-07,  7.3344e-08,  ...,  1.9324e-07,\n",
      "           -2.1687e-07, -1.2123e-07],\n",
      "          ...,\n",
      "          [-2.4005e-07, -4.4894e-09, -4.0040e-08,  ..., -2.6967e-07,\n",
      "            1.6164e-07,  4.4678e-09],\n",
      "          [-3.6670e-09,  1.1470e-07,  1.3444e-08,  ..., -1.9295e-08,\n",
      "           -1.5533e-08, -9.0350e-08],\n",
      "          [ 7.7571e-08, -6.9927e-08,  2.8256e-08,  ..., -1.1589e-08,\n",
      "           -6.4872e-08,  5.8316e-09]],\n",
      "\n",
      "         [[ 7.6872e-08, -9.6452e-08,  1.0939e-07,  ..., -7.1994e-07,\n",
      "           -1.6274e-07, -3.9409e-07],\n",
      "          [ 1.2037e-07,  2.1654e-08, -3.0088e-10,  ..., -1.2490e-06,\n",
      "            1.6100e-07, -2.7058e-07],\n",
      "          [ 1.4431e-07,  2.2099e-07, -2.0804e-09,  ..., -2.1888e-07,\n",
      "           -1.9463e-07, -4.7116e-09],\n",
      "          ...,\n",
      "          [ 1.4694e-07,  1.8986e-08, -8.8773e-08,  ..., -1.7820e-07,\n",
      "           -5.7654e-08, -7.3517e-08],\n",
      "          [-2.7604e-08, -1.2948e-07, -5.7121e-09,  ...,  1.1615e-08,\n",
      "            5.9355e-09,  1.3180e-07],\n",
      "          [-2.2223e-08, -3.4268e-09,  1.8169e-08,  ...,  7.4955e-08,\n",
      "            3.4091e-08,  5.9032e-08]],\n",
      "\n",
      "         [[-5.7108e-08,  2.0735e-07, -6.3678e-08,  ..., -8.6454e-08,\n",
      "            1.9297e-07, -4.0123e-07],\n",
      "          [ 7.9083e-08, -2.9923e-07, -1.3340e-07,  ..., -8.1643e-08,\n",
      "           -7.7557e-08,  2.6240e-08],\n",
      "          [ 2.9742e-07,  7.3309e-08,  1.6771e-08,  ...,  4.5923e-07,\n",
      "           -2.4302e-07, -5.0685e-08],\n",
      "          ...,\n",
      "          [ 1.0131e-07, -1.2117e-07, -6.9504e-08,  ...,  4.8831e-08,\n",
      "           -3.0544e-08,  1.3316e-07],\n",
      "          [ 4.3970e-08,  6.6381e-09,  4.1235e-08,  ..., -2.0347e-08,\n",
      "           -3.9405e-08, -1.7904e-08],\n",
      "          [-1.8833e-08,  7.8789e-08, -6.2044e-09,  ...,  4.5924e-08,\n",
      "            3.1572e-08, -4.0527e-08]]]])\n",
      "ipdb> glparam.model[0]\n",
      "*** AttributeError: 'global_parameters' object has no attribute 'model'\n",
      "ipdb> glparam.net[0]\n",
      "Sequential(\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  (4): Sequential(\n",
      "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  (7): Sequential(\n",
      "    (1): Sequential(\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (7): Sequential(\n",
      "        (1): Sequential(\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          )\n",
      "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "          (4): Sequential(\n",
      "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "          (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): LeakyReLU(negative_slope=0.2, inplace)\n",
      "          (7): Upsample(scale_factor=2, mode=bilinear)\n",
      "        )\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Sequential(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.2, inplace)\n",
      "        (6): Sequential(\n",
      "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      )\n",
      "      (8): Upsample(scale_factor=2, mode=bilinear)\n",
      "    )\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (6): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (8): Upsample(scale_factor=2, mode=bilinear)\n",
      ")\n",
      "ipdb> glparam.model[1]\n",
      "*** AttributeError: 'global_parameters' object has no attribute 'model'\n",
      "ipdb> glparam.net[1]\n",
      "BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ipdb> glparam.net[1].grad\n",
      "*** AttributeError: 'BatchNorm2d' object has no attribute 'grad'\n",
      "ipdb> glparam.net[2]\n",
      "Sequential(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "ipdb> glparam.net[2].grad\n",
      "*** AttributeError: 'Sequential' object has no attribute 'grad'\n",
      "ipdb> glparam.net[1].data\n",
      "*** AttributeError: 'BatchNorm2d' object has no attribute 'data'\n",
      "ipdb> glparam.net[1].weight\n",
      "Parameter containing:\n",
      "tensor([0.6031, 0.3523, 0.8668, 0.9546, 0.9566, 0.4952, 0.0265, 0.1168, 0.6043,\n",
      "        0.3174, 0.5145, 0.1887, 0.7667, 0.8414, 0.6921, 0.4968],\n",
      "       requires_grad=True)\n",
      "ipdb> glparam.net[2].weight\n",
      "*** AttributeError: 'Sequential' object has no attribute 'weight'\n",
      "ipdb> glparam.net[2].parameters\n",
      "<bound method Module.parameters of Sequential(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")>\n",
      "ipdb> glparam.net[2].parameters[2]\n",
      "*** TypeError: 'method' object is not subscriptable\n",
      "ipdb> glparam.net[2].parameters\n",
      "<bound method Module.parameters of Sequential(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")>\n",
      "ipdb> glparam.net[2].parameters[1-\n",
      "*** SyntaxError: unexpected EOF while parsing\n",
      "ipdb> glparam.net[2].parameters[1]\n",
      "*** TypeError: 'method' object is not subscriptable\n",
      "ipdb> glparam.net[2].parameters\n",
      "<bound method Module.parameters of Sequential(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")>\n",
      "ipdb> glparam.net[2].parameters[0]\n",
      "*** TypeError: 'method' object is not subscriptable\n",
      "ipdb> glparam.net[2].parameters\n",
      "<bound method Module.parameters of Sequential(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")>\n",
      "ipdb> glparam.net[2]\n",
      "Sequential(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "ipdb> glparam.net[2][1]\n",
      "*** IndexError: index 1 is out of range\n",
      "ipdb> glparam.net[2][0]\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ipdb> glparam.net[2][0].grad\n",
      "*** AttributeError: 'Conv2d' object has no attribute 'grad'\n",
      "ipdb> glparam.net[2][0].weight\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0334,  0.0298,  0.0430],\n",
      "          [-0.0258,  0.0323, -0.0725],\n",
      "          [-0.0229,  0.0604,  0.0061]],\n",
      "\n",
      "         [[-0.0099, -0.0652,  0.0099],\n",
      "          [-0.0067,  0.0544, -0.0521],\n",
      "          [ 0.0289, -0.0447, -0.0339]],\n",
      "\n",
      "         [[ 0.0310, -0.0816,  0.0829],\n",
      "          [-0.0576,  0.0567,  0.0719],\n",
      "          [ 0.0824, -0.0325, -0.0732]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0011, -0.0751,  0.0541],\n",
      "          [-0.0486,  0.0807,  0.0354],\n",
      "          [-0.0469, -0.0409,  0.0776]],\n",
      "\n",
      "         [[-0.0742,  0.0661, -0.0686],\n",
      "          [-0.0521, -0.0229, -0.0200],\n",
      "          [-0.0344,  0.0659, -0.0236]],\n",
      "\n",
      "         [[ 0.0462, -0.0714,  0.0494],\n",
      "          [ 0.0581,  0.0001, -0.0004],\n",
      "          [-0.0720, -0.0225, -0.0528]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0772, -0.0743, -0.0082],\n",
      "          [-0.0740,  0.0109, -0.0054],\n",
      "          [ 0.0513,  0.0182, -0.0734]],\n",
      "\n",
      "         [[-0.0786,  0.0425,  0.0384],\n",
      "          [ 0.0672, -0.0687, -0.0514],\n",
      "          [ 0.0785, -0.0614, -0.0823]],\n",
      "\n",
      "         [[ 0.0415,  0.0114, -0.0471],\n",
      "          [-0.0072,  0.0342,  0.0714],\n",
      "          [ 0.0066,  0.0717,  0.0527]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0672,  0.0668,  0.0264],\n",
      "          [-0.0429, -0.0203,  0.0617],\n",
      "          [ 0.0075, -0.0710,  0.0704]],\n",
      "\n",
      "         [[-0.0722,  0.0188, -0.0570],\n",
      "          [-0.0752,  0.0032,  0.0074],\n",
      "          [-0.0289,  0.0138,  0.0170]],\n",
      "\n",
      "         [[ 0.0557, -0.0808,  0.0257],\n",
      "          [-0.0339, -0.0049, -0.0667],\n",
      "          [-0.0597,  0.0361, -0.0615]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0380, -0.0712, -0.0624],\n",
      "          [ 0.0510,  0.0717,  0.0064],\n",
      "          [-0.0391,  0.0313, -0.0163]],\n",
      "\n",
      "         [[ 0.0041, -0.0058, -0.0760],\n",
      "          [-0.0742,  0.0714, -0.0748],\n",
      "          [-0.0453, -0.0085, -0.0793]],\n",
      "\n",
      "         [[-0.0738, -0.0130,  0.0157],\n",
      "          [-0.0130,  0.0462, -0.0404],\n",
      "          [ 0.0416,  0.0372,  0.0353]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0556, -0.0117, -0.0637],\n",
      "          [ 0.0163, -0.0784,  0.0747],\n",
      "          [ 0.0323, -0.0804, -0.0162]],\n",
      "\n",
      "         [[-0.0731, -0.0546, -0.0385],\n",
      "          [ 0.0616,  0.0475, -0.0287],\n",
      "          [-0.0533,  0.0064, -0.0427]],\n",
      "\n",
      "         [[ 0.0587,  0.0068, -0.0430],\n",
      "          [-0.0503, -0.0680,  0.0624],\n",
      "          [-0.0614, -0.0758,  0.0591]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0149,  0.0616, -0.0497],\n",
      "          [ 0.0009,  0.0016,  0.0434],\n",
      "          [-0.0279,  0.0534,  0.0748]],\n",
      "\n",
      "         [[ 0.0604,  0.0537, -0.0586],\n",
      "          [ 0.0309,  0.0311,  0.0195],\n",
      "          [-0.0740, -0.0760, -0.0813]],\n",
      "\n",
      "         [[ 0.0792,  0.0710, -0.0057],\n",
      "          [ 0.0002, -0.0108, -0.0065],\n",
      "          [-0.0003, -0.0465,  0.0743]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0211, -0.0651,  0.0068],\n",
      "          [ 0.0624,  0.0726,  0.0108],\n",
      "          [-0.0187,  0.0705,  0.0452]],\n",
      "\n",
      "         [[ 0.0382, -0.0187, -0.0710],\n",
      "          [ 0.0415, -0.0034, -0.0015],\n",
      "          [-0.0660, -0.0335, -0.0001]],\n",
      "\n",
      "         [[ 0.0252, -0.0257, -0.0361],\n",
      "          [ 0.0087, -0.0674,  0.0304],\n",
      "          [ 0.0193, -0.0603, -0.0653]]],\n",
      "\n",
      "\n",
      "        [[[-0.0375, -0.0368, -0.0380],\n",
      "          [ 0.0355,  0.0380,  0.0813],\n",
      "          [-0.0012, -0.0809,  0.0723]],\n",
      "\n",
      "         [[-0.0580,  0.0220, -0.0030],\n",
      "          [ 0.0543,  0.0143, -0.0684],\n",
      "          [-0.0393, -0.0258, -0.0632]],\n",
      "\n",
      "         [[-0.0488,  0.0773,  0.0561],\n",
      "          [ 0.0829,  0.0057, -0.0446],\n",
      "          [-0.0272,  0.0062,  0.0287]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0725,  0.0119, -0.0231],\n",
      "          [-0.0035,  0.0492, -0.0491],\n",
      "          [ 0.0512, -0.0811,  0.0499]],\n",
      "\n",
      "         [[ 0.0564, -0.0313,  0.0049],\n",
      "          [ 0.0216, -0.0618, -0.0153],\n",
      "          [-0.0331,  0.0765,  0.0527]],\n",
      "\n",
      "         [[ 0.0662,  0.0558, -0.0411],\n",
      "          [ 0.0106, -0.0313, -0.0658],\n",
      "          [-0.0548,  0.0333,  0.0397]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0377, -0.0035, -0.0420],\n",
      "          [ 0.0008,  0.0789,  0.0214],\n",
      "          [ 0.0053, -0.0758, -0.0815]],\n",
      "\n",
      "         [[-0.0161, -0.0731,  0.0451],\n",
      "          [-0.0567, -0.0227,  0.0372],\n",
      "          [ 0.0460,  0.0127,  0.0649]],\n",
      "\n",
      "         [[-0.0271,  0.0798,  0.0420],\n",
      "          [-0.0255, -0.0329,  0.0361],\n",
      "          [ 0.0462, -0.0296,  0.0045]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0726, -0.0592,  0.0207],\n",
      "          [-0.0095, -0.0498, -0.0421],\n",
      "          [ 0.0472, -0.0524, -0.0315]],\n",
      "\n",
      "         [[-0.0472, -0.0241,  0.0261],\n",
      "          [-0.0398,  0.0063, -0.0458],\n",
      "          [-0.0107,  0.0692, -0.0656]],\n",
      "\n",
      "         [[-0.0009,  0.0621, -0.0557],\n",
      "          [ 0.0024, -0.0659, -0.0093],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [-0.0035, -0.0059, -0.0554]]]], requires_grad=True)\n",
      "ipdb> glparam.net[2][0].weight.grad\n",
      "tensor([[[[-5.6845e-06,  3.3405e-06,  1.0355e-05],\n",
      "          [ 1.4907e-05,  2.6446e-05,  3.5287e-05],\n",
      "          [ 3.2837e-05,  4.5812e-05,  5.5732e-05]],\n",
      "\n",
      "         [[ 5.5808e-05,  6.3223e-05,  6.8482e-05],\n",
      "          [ 7.0558e-05,  7.9171e-05,  8.4847e-05],\n",
      "          [ 8.1478e-05,  9.0887e-05,  9.6603e-05]],\n",
      "\n",
      "         [[ 1.9398e-04,  2.1412e-04,  2.1874e-04],\n",
      "          [ 2.2372e-04,  2.4952e-04,  2.5885e-04],\n",
      "          [ 2.3946e-04,  2.6962e-04,  2.8303e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6346e-05,  8.4575e-06, -2.7543e-06],\n",
      "          [ 3.6035e-05,  3.0402e-05,  2.0166e-05],\n",
      "          [ 4.9293e-05,  4.6063e-05,  3.7428e-05]],\n",
      "\n",
      "         [[ 5.5071e-05,  3.0745e-05,  5.0483e-06],\n",
      "          [ 3.3234e-05,  5.7691e-06, -2.2066e-05],\n",
      "          [ 5.5956e-06, -2.2662e-05, -4.9337e-05]],\n",
      "\n",
      "         [[ 8.9389e-06,  9.0128e-06,  1.1829e-05],\n",
      "          [ 1.8891e-07,  2.8809e-06,  8.0722e-06],\n",
      "          [-5.5461e-06, -1.5127e-07,  7.0644e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4604e-06,  1.5925e-06,  1.6155e-06],\n",
      "          [ 1.9187e-06,  2.1289e-06,  2.2208e-06],\n",
      "          [ 2.2276e-06,  2.4882e-06,  2.6325e-06]],\n",
      "\n",
      "         [[ 2.0296e-06,  2.1011e-06,  2.1047e-06],\n",
      "          [ 2.2823e-06,  2.3699e-06,  2.3762e-06],\n",
      "          [ 2.4141e-06,  2.5118e-06,  2.5161e-06]],\n",
      "\n",
      "         [[ 8.7577e-06,  9.3828e-06,  9.4373e-06],\n",
      "          [ 9.1856e-06,  9.9299e-06,  1.0109e-05],\n",
      "          [ 9.1465e-06,  9.9732e-06,  1.0254e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4148e-06,  2.0792e-06,  1.5752e-06],\n",
      "          [ 2.3644e-06,  2.0575e-06,  1.5905e-06],\n",
      "          [ 2.1583e-06,  1.8879e-06,  1.4756e-06]],\n",
      "\n",
      "         [[-2.5152e-06, -3.2147e-06, -3.7434e-06],\n",
      "          [-3.1223e-06, -3.9123e-06, -4.5014e-06],\n",
      "          [-3.6484e-06, -4.4567e-06, -5.0274e-06]],\n",
      "\n",
      "         [[ 1.1498e-06,  1.3911e-06,  1.5386e-06],\n",
      "          [ 9.1008e-07,  1.2126e-06,  1.4213e-06],\n",
      "          [ 6.9191e-07,  1.0399e-06,  1.2937e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0887e-04,  2.6883e-04,  2.2051e-04],\n",
      "          [ 3.3308e-04,  2.9176e-04,  2.4055e-04],\n",
      "          [ 3.5164e-04,  3.1369e-04,  2.6419e-04]],\n",
      "\n",
      "         [[ 4.8882e-05,  3.4906e-05,  2.2432e-05],\n",
      "          [ 3.5790e-05,  2.2352e-05,  1.1515e-05],\n",
      "          [ 2.6461e-05,  1.4954e-05,  6.9721e-06]],\n",
      "\n",
      "         [[ 4.1699e-04,  4.1966e-04,  3.9951e-04],\n",
      "          [ 4.9168e-04,  5.0331e-04,  4.8286e-04],\n",
      "          [ 5.4745e-04,  5.6812e-04,  5.5160e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0894e-04,  2.9406e-04,  2.6904e-04],\n",
      "          [ 3.1124e-04,  2.9907e-04,  2.7741e-04],\n",
      "          [ 3.0244e-04,  2.9675e-04,  2.8289e-04]],\n",
      "\n",
      "         [[-1.5086e-05,  5.9792e-05,  1.3176e-04],\n",
      "          [ 9.7147e-07,  8.1073e-05,  1.5610e-04],\n",
      "          [ 9.3482e-06,  8.7001e-05,  1.5757e-04]],\n",
      "\n",
      "         [[-1.2401e-05,  1.7852e-05,  3.4762e-05],\n",
      "          [-7.3443e-06,  2.0282e-05,  3.1996e-05],\n",
      "          [-1.3273e-05,  1.0239e-05,  1.7832e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.3671e-05, -4.2393e-05, -6.2000e-05],\n",
      "          [-1.1570e-05, -2.8818e-05, -4.7387e-05],\n",
      "          [ 2.7031e-06, -1.1931e-05, -2.8369e-05]],\n",
      "\n",
      "         [[-1.8668e-05, -2.5582e-05, -3.1119e-05],\n",
      "          [-1.9009e-05, -2.5318e-05, -2.9929e-05],\n",
      "          [-1.6684e-05, -2.1778e-05, -2.5137e-05]],\n",
      "\n",
      "         [[ 1.8740e-04,  2.0327e-04,  1.9966e-04],\n",
      "          [ 2.3559e-04,  2.5917e-04,  2.5891e-04],\n",
      "          [ 2.7222e-04,  3.0293e-04,  3.0705e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2968e-05, -1.1670e-04, -1.6004e-04],\n",
      "          [-8.3510e-05, -1.2741e-04, -1.6951e-04],\n",
      "          [-8.9131e-05, -1.2923e-04, -1.6657e-04]],\n",
      "\n",
      "         [[ 6.9741e-05,  9.2826e-05,  1.0954e-04],\n",
      "          [ 7.1136e-05,  9.1829e-05,  1.0650e-04],\n",
      "          [ 6.3544e-05,  8.1374e-05,  9.4543e-05]],\n",
      "\n",
      "         [[ 7.8247e-05,  9.3149e-05,  1.0317e-04],\n",
      "          [ 7.9161e-05,  9.6736e-05,  1.0822e-04],\n",
      "          [ 7.6071e-05,  9.5549e-05,  1.0823e-04]]],\n",
      "\n",
      "\n",
      "        [[[-7.8705e-04, -8.3456e-04, -8.5626e-04],\n",
      "          [-9.5458e-04, -1.0241e-03, -1.0615e-03],\n",
      "          [-1.0834e-03, -1.1682e-03, -1.2161e-03]],\n",
      "\n",
      "         [[-8.0349e-04, -8.3636e-04, -8.3796e-04],\n",
      "          [-9.0827e-04, -9.4663e-04, -9.4928e-04],\n",
      "          [-9.7221e-04, -1.0144e-03, -1.0181e-03]],\n",
      "\n",
      "         [[-1.9610e-03, -2.0420e-03, -2.0338e-03],\n",
      "          [-2.1303e-03, -2.2598e-03, -2.2989e-03],\n",
      "          [-2.2006e-03, -2.3713e-03, -2.4520e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7986e-03, -1.9039e-03, -1.9271e-03],\n",
      "          [-1.9800e-03, -2.1132e-03, -2.1557e-03],\n",
      "          [-2.0692e-03, -2.2204e-03, -2.2789e-03]],\n",
      "\n",
      "         [[ 3.0164e-04,  3.5218e-04,  3.8540e-04],\n",
      "          [ 4.7675e-04,  5.5563e-04,  6.1021e-04],\n",
      "          [ 6.3053e-04,  7.2717e-04,  7.9350e-04]],\n",
      "\n",
      "         [[ 6.0064e-05,  2.3722e-05, -1.5551e-05],\n",
      "          [ 1.6174e-04,  1.0854e-04,  4.9992e-05],\n",
      "          [ 2.6219e-04,  1.9264e-04,  1.1536e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7300e-04,  7.6541e-04,  7.2099e-04],\n",
      "          [ 7.5696e-04,  7.4898e-04,  7.0571e-04],\n",
      "          [ 6.9560e-04,  6.8715e-04,  6.4702e-04]],\n",
      "\n",
      "         [[ 3.3164e-04,  3.1837e-04,  2.9471e-04],\n",
      "          [ 3.3186e-04,  3.1641e-04,  2.9060e-04],\n",
      "          [ 3.1551e-04,  2.9951e-04,  2.7351e-04]],\n",
      "\n",
      "         [[ 1.6734e-03,  1.7023e-03,  1.6373e-03],\n",
      "          [ 1.6676e-03,  1.7061e-03,  1.6460e-03],\n",
      "          [ 1.5753e-03,  1.6221e-03,  1.5712e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8388e-04,  2.6557e-04,  1.4190e-04],\n",
      "          [ 3.7175e-04,  2.4937e-04,  1.2372e-04],\n",
      "          [ 3.3537e-04,  2.1771e-04,  9.8208e-05]],\n",
      "\n",
      "         [[-6.3633e-04, -6.6729e-04, -6.7937e-04],\n",
      "          [-6.7601e-04, -7.1297e-04, -7.2799e-04],\n",
      "          [-6.8692e-04, -7.2686e-04, -7.4233e-04]],\n",
      "\n",
      "         [[-5.3952e-05, -4.6290e-05, -4.0857e-05],\n",
      "          [-6.3421e-05, -4.9680e-05, -3.9629e-05],\n",
      "          [-6.6957e-05, -4.7532e-05, -3.3068e-05]]]])\n",
      "ipdb> glparam.net[7][0].weight.grad\n",
      "*** TypeError: 'LeakyReLU' object does not support indexing\n",
      "ipdb> glparam.net[6][0].weight.grad\n",
      "*** TypeError: 'BatchNorm2d' object does not support indexing\n",
      "ipdb> glparam.net[5][0].weight.grad\n",
      "tensor([[[[-2.8551e-05]],\n",
      "\n",
      "         [[ 2.3233e-07]],\n",
      "\n",
      "         [[ 4.6336e-05]],\n",
      "\n",
      "         [[-9.0355e-05]],\n",
      "\n",
      "         [[-2.7093e-04]],\n",
      "\n",
      "         [[-3.5651e-05]],\n",
      "\n",
      "         [[ 1.6104e-05]],\n",
      "\n",
      "         [[-5.0529e-05]],\n",
      "\n",
      "         [[-1.9333e-04]],\n",
      "\n",
      "         [[ 1.5466e-04]],\n",
      "\n",
      "         [[-1.7988e-05]],\n",
      "\n",
      "         [[-2.0246e-06]],\n",
      "\n",
      "         [[-2.8561e-04]],\n",
      "\n",
      "         [[-5.0106e-05]],\n",
      "\n",
      "         [[-8.8749e-06]],\n",
      "\n",
      "         [[ 7.6571e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5609e-05]],\n",
      "\n",
      "         [[ 1.6448e-07]],\n",
      "\n",
      "         [[-9.4266e-05]],\n",
      "\n",
      "         [[-1.5036e-04]],\n",
      "\n",
      "         [[ 2.5479e-04]],\n",
      "\n",
      "         [[-9.6690e-05]],\n",
      "\n",
      "         [[-1.1251e-05]],\n",
      "\n",
      "         [[ 2.8700e-05]],\n",
      "\n",
      "         [[ 1.7768e-04]],\n",
      "\n",
      "         [[ 2.4522e-04]],\n",
      "\n",
      "         [[ 2.0738e-05]],\n",
      "\n",
      "         [[ 1.8040e-05]],\n",
      "\n",
      "         [[-7.2639e-04]],\n",
      "\n",
      "         [[ 3.9374e-05]],\n",
      "\n",
      "         [[ 3.3298e-05]],\n",
      "\n",
      "         [[-2.5962e-05]]],\n",
      "\n",
      "\n",
      "        [[[-3.8167e-06]],\n",
      "\n",
      "         [[-2.2239e-08]],\n",
      "\n",
      "         [[-1.7466e-05]],\n",
      "\n",
      "         [[ 3.8223e-06]],\n",
      "\n",
      "         [[-9.1646e-06]],\n",
      "\n",
      "         [[ 1.3081e-05]],\n",
      "\n",
      "         [[ 1.5743e-06]],\n",
      "\n",
      "         [[-2.9665e-06]],\n",
      "\n",
      "         [[-2.6565e-06]],\n",
      "\n",
      "         [[ 4.4531e-05]],\n",
      "\n",
      "         [[ 3.4502e-06]],\n",
      "\n",
      "         [[ 1.2949e-06]],\n",
      "\n",
      "         [[-9.2635e-05]],\n",
      "\n",
      "         [[ 1.2009e-06]],\n",
      "\n",
      "         [[ 5.2454e-06]],\n",
      "\n",
      "         [[-1.5620e-05]]],\n",
      "\n",
      "\n",
      "        [[[-2.7273e-05]],\n",
      "\n",
      "         [[-6.4367e-07]],\n",
      "\n",
      "         [[ 1.0138e-04]],\n",
      "\n",
      "         [[-6.0295e-04]],\n",
      "\n",
      "         [[-6.9963e-04]],\n",
      "\n",
      "         [[-2.3288e-04]],\n",
      "\n",
      "         [[-1.1157e-05]],\n",
      "\n",
      "         [[ 6.4119e-05]],\n",
      "\n",
      "         [[-9.1695e-05]],\n",
      "\n",
      "         [[-1.2201e-05]],\n",
      "\n",
      "         [[-7.6039e-05]],\n",
      "\n",
      "         [[-2.4139e-06]],\n",
      "\n",
      "         [[ 4.0574e-04]],\n",
      "\n",
      "         [[-9.4509e-05]],\n",
      "\n",
      "         [[-4.3227e-04]],\n",
      "\n",
      "         [[-2.7827e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9673e-05]],\n",
      "\n",
      "         [[ 2.8269e-06]],\n",
      "\n",
      "         [[ 4.0940e-04]],\n",
      "\n",
      "         [[-1.2591e-03]],\n",
      "\n",
      "         [[ 6.9213e-04]],\n",
      "\n",
      "         [[-6.6537e-04]],\n",
      "\n",
      "         [[ 3.3592e-04]],\n",
      "\n",
      "         [[-4.2189e-05]],\n",
      "\n",
      "         [[ 1.8119e-04]],\n",
      "\n",
      "         [[ 8.1565e-04]],\n",
      "\n",
      "         [[-1.8440e-04]],\n",
      "\n",
      "         [[ 4.8483e-05]],\n",
      "\n",
      "         [[-1.4010e-03]],\n",
      "\n",
      "         [[ 1.4894e-04]],\n",
      "\n",
      "         [[ 1.1960e-04]],\n",
      "\n",
      "         [[ 4.6973e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.1163e-05]],\n",
      "\n",
      "         [[-3.3853e-07]],\n",
      "\n",
      "         [[ 1.6538e-05]],\n",
      "\n",
      "         [[ 2.6688e-04]],\n",
      "\n",
      "         [[-1.8153e-04]],\n",
      "\n",
      "         [[ 1.0277e-04]],\n",
      "\n",
      "         [[-5.6156e-05]],\n",
      "\n",
      "         [[-7.5536e-05]],\n",
      "\n",
      "         [[-1.4724e-04]],\n",
      "\n",
      "         [[ 9.6432e-05]],\n",
      "\n",
      "         [[ 3.7906e-06]],\n",
      "\n",
      "         [[-2.1238e-06]],\n",
      "\n",
      "         [[ 2.2481e-05]],\n",
      "\n",
      "         [[-3.8122e-05]],\n",
      "\n",
      "         [[-3.3270e-05]],\n",
      "\n",
      "         [[-2.2416e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.6942e-05]],\n",
      "\n",
      "         [[-6.7169e-07]],\n",
      "\n",
      "         [[-2.6911e-04]],\n",
      "\n",
      "         [[ 4.5718e-04]],\n",
      "\n",
      "         [[-2.0674e-04]],\n",
      "\n",
      "         [[ 3.0370e-04]],\n",
      "\n",
      "         [[-1.9260e-04]],\n",
      "\n",
      "         [[-2.5184e-05]],\n",
      "\n",
      "         [[-1.0167e-04]],\n",
      "\n",
      "         [[-3.4770e-04]],\n",
      "\n",
      "         [[ 1.4488e-04]],\n",
      "\n",
      "         [[-2.9588e-05]],\n",
      "\n",
      "         [[-4.9140e-04]],\n",
      "\n",
      "         [[-6.7234e-05]],\n",
      "\n",
      "         [[ 7.8814e-05]],\n",
      "\n",
      "         [[ 1.4874e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.8739e-05]],\n",
      "\n",
      "         [[-3.9502e-07]],\n",
      "\n",
      "         [[ 1.1721e-04]],\n",
      "\n",
      "         [[-4.7310e-04]],\n",
      "\n",
      "         [[-1.5767e-04]],\n",
      "\n",
      "         [[-2.5387e-04]],\n",
      "\n",
      "         [[-2.3296e-05]],\n",
      "\n",
      "         [[ 6.8649e-05]],\n",
      "\n",
      "         [[ 5.0150e-05]],\n",
      "\n",
      "         [[ 3.4616e-04]],\n",
      "\n",
      "         [[-9.7484e-05]],\n",
      "\n",
      "         [[ 1.8844e-05]],\n",
      "\n",
      "         [[ 2.6350e-04]],\n",
      "\n",
      "         [[-3.8896e-05]],\n",
      "\n",
      "         [[-2.0812e-04]],\n",
      "\n",
      "         [[-1.5996e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.9947e-04]],\n",
      "\n",
      "         [[-2.0340e-06]],\n",
      "\n",
      "         [[-4.6756e-04]],\n",
      "\n",
      "         [[ 1.4710e-03]],\n",
      "\n",
      "         [[-3.6776e-03]],\n",
      "\n",
      "         [[ 7.4449e-04]],\n",
      "\n",
      "         [[ 4.5923e-05]],\n",
      "\n",
      "         [[-3.5412e-04]],\n",
      "\n",
      "         [[-1.5628e-03]],\n",
      "\n",
      "         [[ 1.9593e-04]],\n",
      "\n",
      "         [[-7.4646e-05]],\n",
      "\n",
      "         [[-7.0156e-05]],\n",
      "\n",
      "         [[ 1.2441e-03]],\n",
      "\n",
      "         [[-5.6162e-04]],\n",
      "\n",
      "         [[-8.2182e-04]],\n",
      "\n",
      "         [[-9.2237e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.8959e-04]],\n",
      "\n",
      "         [[-1.2240e-06]],\n",
      "\n",
      "         [[-2.0771e-03]],\n",
      "\n",
      "         [[-2.9894e-04]],\n",
      "\n",
      "         [[-2.3521e-03]],\n",
      "\n",
      "         [[ 9.4389e-05]],\n",
      "\n",
      "         [[ 1.7669e-04]],\n",
      "\n",
      "         [[ 5.4417e-04]],\n",
      "\n",
      "         [[-1.1409e-04]],\n",
      "\n",
      "         [[ 1.4401e-03]],\n",
      "\n",
      "         [[ 2.9117e-04]],\n",
      "\n",
      "         [[ 1.2268e-05]],\n",
      "\n",
      "         [[-1.6319e-03]],\n",
      "\n",
      "         [[-2.2742e-04]],\n",
      "\n",
      "         [[ 2.5094e-04]],\n",
      "\n",
      "         [[ 3.2338e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2982e-04]],\n",
      "\n",
      "         [[ 5.0252e-06]],\n",
      "\n",
      "         [[ 4.2155e-04]],\n",
      "\n",
      "         [[-2.6863e-03]],\n",
      "\n",
      "         [[ 7.9641e-04]],\n",
      "\n",
      "         [[-5.7338e-04]],\n",
      "\n",
      "         [[ 3.4691e-04]],\n",
      "\n",
      "         [[ 2.9948e-04]],\n",
      "\n",
      "         [[ 2.4946e-04]],\n",
      "\n",
      "         [[ 1.2795e-03]],\n",
      "\n",
      "         [[-1.4235e-04]],\n",
      "\n",
      "         [[ 4.8965e-05]],\n",
      "\n",
      "         [[-1.1645e-03]],\n",
      "\n",
      "         [[ 1.7193e-04]],\n",
      "\n",
      "         [[-7.4842e-05]],\n",
      "\n",
      "         [[ 1.3535e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1054e-06]],\n",
      "\n",
      "         [[-6.9207e-08]],\n",
      "\n",
      "         [[-2.9429e-05]],\n",
      "\n",
      "         [[-5.9653e-05]],\n",
      "\n",
      "         [[-2.7254e-05]],\n",
      "\n",
      "         [[ 3.0471e-07]],\n",
      "\n",
      "         [[ 2.7869e-05]],\n",
      "\n",
      "         [[ 1.3524e-05]],\n",
      "\n",
      "         [[ 1.6162e-05]],\n",
      "\n",
      "         [[ 2.9657e-05]],\n",
      "\n",
      "         [[-6.8154e-06]],\n",
      "\n",
      "         [[ 3.3950e-06]],\n",
      "\n",
      "         [[ 4.2422e-05]],\n",
      "\n",
      "         [[ 2.4699e-06]],\n",
      "\n",
      "         [[ 2.1487e-05]],\n",
      "\n",
      "         [[ 7.5354e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 7.4628e-07]],\n",
      "\n",
      "         [[-1.6824e-07]],\n",
      "\n",
      "         [[-2.6850e-05]],\n",
      "\n",
      "         [[-9.9007e-05]],\n",
      "\n",
      "         [[-3.3755e-05]],\n",
      "\n",
      "         [[-3.4537e-05]],\n",
      "\n",
      "         [[-8.6130e-06]],\n",
      "\n",
      "         [[ 5.2589e-05]],\n",
      "\n",
      "         [[ 5.5887e-05]],\n",
      "\n",
      "         [[ 1.4034e-05]],\n",
      "\n",
      "         [[ 7.8685e-06]],\n",
      "\n",
      "         [[ 1.6430e-06]],\n",
      "\n",
      "         [[-4.0026e-05]],\n",
      "\n",
      "         [[-7.1152e-06]],\n",
      "\n",
      "         [[-4.2161e-05]],\n",
      "\n",
      "         [[-4.6837e-06]]],\n",
      "\n",
      "\n",
      "        [[[-4.6317e-04]],\n",
      "\n",
      "         [[ 7.3274e-07]],\n",
      "\n",
      "         [[ 1.0461e-03]],\n",
      "\n",
      "         [[ 1.6865e-03]],\n",
      "\n",
      "         [[-5.4770e-03]],\n",
      "\n",
      "         [[ 1.5968e-03]],\n",
      "\n",
      "         [[ 1.5103e-03]],\n",
      "\n",
      "         [[-8.6500e-04]],\n",
      "\n",
      "         [[-4.2895e-03]],\n",
      "\n",
      "         [[-3.9420e-04]],\n",
      "\n",
      "         [[-3.9191e-04]],\n",
      "\n",
      "         [[-1.7353e-04]],\n",
      "\n",
      "         [[ 8.4059e-03]],\n",
      "\n",
      "         [[-1.1087e-03]],\n",
      "\n",
      "         [[-5.4620e-05]],\n",
      "\n",
      "         [[ 1.7691e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.7136e-06]],\n",
      "\n",
      "         [[-1.8708e-07]],\n",
      "\n",
      "         [[-2.6209e-04]],\n",
      "\n",
      "         [[-6.8155e-05]],\n",
      "\n",
      "         [[ 4.1049e-05]],\n",
      "\n",
      "         [[-6.3640e-05]],\n",
      "\n",
      "         [[ 1.9450e-05]],\n",
      "\n",
      "         [[ 5.9722e-05]],\n",
      "\n",
      "         [[ 1.2617e-04]],\n",
      "\n",
      "         [[ 4.0881e-04]],\n",
      "\n",
      "         [[ 3.0875e-05]],\n",
      "\n",
      "         [[ 2.2015e-05]],\n",
      "\n",
      "         [[-5.3192e-04]],\n",
      "\n",
      "         [[ 1.3117e-05]],\n",
      "\n",
      "         [[ 4.6160e-05]],\n",
      "\n",
      "         [[-1.7579e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.0512e-06]],\n",
      "\n",
      "         [[-3.0187e-09]],\n",
      "\n",
      "         [[-8.9084e-06]],\n",
      "\n",
      "         [[ 3.0808e-05]],\n",
      "\n",
      "         [[-1.3795e-05]],\n",
      "\n",
      "         [[ 5.7935e-06]],\n",
      "\n",
      "         [[-2.2487e-06]],\n",
      "\n",
      "         [[ 4.7931e-06]],\n",
      "\n",
      "         [[ 2.1608e-06]],\n",
      "\n",
      "         [[ 1.5762e-05]],\n",
      "\n",
      "         [[-8.5775e-06]],\n",
      "\n",
      "         [[ 1.2062e-07]],\n",
      "\n",
      "         [[ 1.9827e-05]],\n",
      "\n",
      "         [[ 2.2274e-06]],\n",
      "\n",
      "         [[-3.2689e-05]],\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         [[-3.9979e-06]]]])\n",
      "ipdb> glparam.net[4][0].weight.grad\n",
      "*** TypeError: 'LeakyReLU' object does not support indexing\n",
      "ipdb> glparam.net[8][0].weight.grad\n",
      "tensor([[[[0.0039]],\n",
      "\n",
      "         [[0.0066]],\n",
      "\n",
      "         [[0.0005]],\n",
      "\n",
      "         [[0.0132]],\n",
      "\n",
      "         [[0.0051]],\n",
      "\n",
      "         [[0.0029]],\n",
      "\n",
      "         [[0.0075]],\n",
      "\n",
      "         [[0.0074]],\n",
      "\n",
      "         [[0.0162]],\n",
      "\n",
      "         [[0.0200]],\n",
      "\n",
      "         [[0.0132]],\n",
      "\n",
      "         [[0.0007]],\n",
      "\n",
      "         [[0.0022]],\n",
      "\n",
      "         [[0.0174]],\n",
      "\n",
      "         [[0.0083]],\n",
      "\n",
      "         [[0.0100]]],\n",
      "\n",
      "\n",
      "        [[[0.0038]],\n",
      "\n",
      "         [[0.0083]],\n",
      "\n",
      "         [[0.0005]],\n",
      "\n",
      "         [[0.0129]],\n",
      "\n",
      "         [[0.0068]],\n",
      "\n",
      "         [[0.0040]],\n",
      "\n",
      "         [[0.0070]],\n",
      "\n",
      "         [[0.0093]],\n",
      "\n",
      "         [[0.0189]],\n",
      "\n",
      "         [[0.0173]],\n",
      "\n",
      "         [[0.0211]],\n",
      "\n",
      "         [[0.0008]],\n",
      "\n",
      "         [[0.0029]],\n",
      "\n",
      "         [[0.0199]],\n",
      "\n",
      "         [[0.0098]],\n",
      "\n",
      "         [[0.0105]]],\n",
      "\n",
      "\n",
      "        [[[0.0038]],\n",
      "\n",
      "         [[0.0080]],\n",
      "\n",
      "         [[0.0004]],\n",
      "\n",
      "         [[0.0131]],\n",
      "\n",
      "         [[0.0061]],\n",
      "\n",
      "         [[0.0031]],\n",
      "\n",
      "         [[0.0075]],\n",
      "\n",
      "         [[0.0077]],\n",
      "\n",
      "         [[0.0148]],\n",
      "\n",
      "         [[0.0177]],\n",
      "\n",
      "         [[0.0178]],\n",
      "\n",
      "         [[0.0007]],\n",
      "\n",
      "         [[0.0026]],\n",
      "\n",
      "         [[0.0203]],\n",
      "\n",
      "         [[0.0083]],\n",
      "\n",
      "         [[0.0105]]]])\n",
      "ipdb> glparam.net[2][0].weight.grad\n",
      "tensor([[[[-5.6845e-06,  3.3405e-06,  1.0355e-05],\n",
      "          [ 1.4907e-05,  2.6446e-05,  3.5287e-05],\n",
      "          [ 3.2837e-05,  4.5812e-05,  5.5732e-05]],\n",
      "\n",
      "         [[ 5.5808e-05,  6.3223e-05,  6.8482e-05],\n",
      "          [ 7.0558e-05,  7.9171e-05,  8.4847e-05],\n",
      "          [ 8.1478e-05,  9.0887e-05,  9.6603e-05]],\n",
      "\n",
      "         [[ 1.9398e-04,  2.1412e-04,  2.1874e-04],\n",
      "          [ 2.2372e-04,  2.4952e-04,  2.5885e-04],\n",
      "          [ 2.3946e-04,  2.6962e-04,  2.8303e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6346e-05,  8.4575e-06, -2.7543e-06],\n",
      "          [ 3.6035e-05,  3.0402e-05,  2.0166e-05],\n",
      "          [ 4.9293e-05,  4.6063e-05,  3.7428e-05]],\n",
      "\n",
      "         [[ 5.5071e-05,  3.0745e-05,  5.0483e-06],\n",
      "          [ 3.3234e-05,  5.7691e-06, -2.2066e-05],\n",
      "          [ 5.5956e-06, -2.2662e-05, -4.9337e-05]],\n",
      "\n",
      "         [[ 8.9389e-06,  9.0128e-06,  1.1829e-05],\n",
      "          [ 1.8891e-07,  2.8809e-06,  8.0722e-06],\n",
      "          [-5.5461e-06, -1.5127e-07,  7.0644e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4604e-06,  1.5925e-06,  1.6155e-06],\n",
      "          [ 1.9187e-06,  2.1289e-06,  2.2208e-06],\n",
      "          [ 2.2276e-06,  2.4882e-06,  2.6325e-06]],\n",
      "\n",
      "         [[ 2.0296e-06,  2.1011e-06,  2.1047e-06],\n",
      "          [ 2.2823e-06,  2.3699e-06,  2.3762e-06],\n",
      "          [ 2.4141e-06,  2.5118e-06,  2.5161e-06]],\n",
      "\n",
      "         [[ 8.7577e-06,  9.3828e-06,  9.4373e-06],\n",
      "          [ 9.1856e-06,  9.9299e-06,  1.0109e-05],\n",
      "          [ 9.1465e-06,  9.9732e-06,  1.0254e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4148e-06,  2.0792e-06,  1.5752e-06],\n",
      "          [ 2.3644e-06,  2.0575e-06,  1.5905e-06],\n",
      "          [ 2.1583e-06,  1.8879e-06,  1.4756e-06]],\n",
      "\n",
      "         [[-2.5152e-06, -3.2147e-06, -3.7434e-06],\n",
      "          [-3.1223e-06, -3.9123e-06, -4.5014e-06],\n",
      "          [-3.6484e-06, -4.4567e-06, -5.0274e-06]],\n",
      "\n",
      "         [[ 1.1498e-06,  1.3911e-06,  1.5386e-06],\n",
      "          [ 9.1008e-07,  1.2126e-06,  1.4213e-06],\n",
      "          [ 6.9191e-07,  1.0399e-06,  1.2937e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0887e-04,  2.6883e-04,  2.2051e-04],\n",
      "          [ 3.3308e-04,  2.9176e-04,  2.4055e-04],\n",
      "          [ 3.5164e-04,  3.1369e-04,  2.6419e-04]],\n",
      "\n",
      "         [[ 4.8882e-05,  3.4906e-05,  2.2432e-05],\n",
      "          [ 3.5790e-05,  2.2352e-05,  1.1515e-05],\n",
      "          [ 2.6461e-05,  1.4954e-05,  6.9721e-06]],\n",
      "\n",
      "         [[ 4.1699e-04,  4.1966e-04,  3.9951e-04],\n",
      "          [ 4.9168e-04,  5.0331e-04,  4.8286e-04],\n",
      "          [ 5.4745e-04,  5.6812e-04,  5.5160e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0894e-04,  2.9406e-04,  2.6904e-04],\n",
      "          [ 3.1124e-04,  2.9907e-04,  2.7741e-04],\n",
      "          [ 3.0244e-04,  2.9675e-04,  2.8289e-04]],\n",
      "\n",
      "         [[-1.5086e-05,  5.9792e-05,  1.3176e-04],\n",
      "          [ 9.7147e-07,  8.1073e-05,  1.5610e-04],\n",
      "          [ 9.3482e-06,  8.7001e-05,  1.5757e-04]],\n",
      "\n",
      "         [[-1.2401e-05,  1.7852e-05,  3.4762e-05],\n",
      "          [-7.3443e-06,  2.0282e-05,  3.1996e-05],\n",
      "          [-1.3273e-05,  1.0239e-05,  1.7832e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.3671e-05, -4.2393e-05, -6.2000e-05],\n",
      "          [-1.1570e-05, -2.8818e-05, -4.7387e-05],\n",
      "          [ 2.7031e-06, -1.1931e-05, -2.8369e-05]],\n",
      "\n",
      "         [[-1.8668e-05, -2.5582e-05, -3.1119e-05],\n",
      "          [-1.9009e-05, -2.5318e-05, -2.9929e-05],\n",
      "          [-1.6684e-05, -2.1778e-05, -2.5137e-05]],\n",
      "\n",
      "         [[ 1.8740e-04,  2.0327e-04,  1.9966e-04],\n",
      "          [ 2.3559e-04,  2.5917e-04,  2.5891e-04],\n",
      "          [ 2.7222e-04,  3.0293e-04,  3.0705e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2968e-05, -1.1670e-04, -1.6004e-04],\n",
      "          [-8.3510e-05, -1.2741e-04, -1.6951e-04],\n",
      "          [-8.9131e-05, -1.2923e-04, -1.6657e-04]],\n",
      "\n",
      "         [[ 6.9741e-05,  9.2826e-05,  1.0954e-04],\n",
      "          [ 7.1136e-05,  9.1829e-05,  1.0650e-04],\n",
      "          [ 6.3544e-05,  8.1374e-05,  9.4543e-05]],\n",
      "\n",
      "         [[ 7.8247e-05,  9.3149e-05,  1.0317e-04],\n",
      "          [ 7.9161e-05,  9.6736e-05,  1.0822e-04],\n",
      "          [ 7.6071e-05,  9.5549e-05,  1.0823e-04]]],\n",
      "\n",
      "\n",
      "        [[[-7.8705e-04, -8.3456e-04, -8.5626e-04],\n",
      "          [-9.5458e-04, -1.0241e-03, -1.0615e-03],\n",
      "          [-1.0834e-03, -1.1682e-03, -1.2161e-03]],\n",
      "\n",
      "         [[-8.0349e-04, -8.3636e-04, -8.3796e-04],\n",
      "          [-9.0827e-04, -9.4663e-04, -9.4928e-04],\n",
      "          [-9.7221e-04, -1.0144e-03, -1.0181e-03]],\n",
      "\n",
      "         [[-1.9610e-03, -2.0420e-03, -2.0338e-03],\n",
      "          [-2.1303e-03, -2.2598e-03, -2.2989e-03],\n",
      "          [-2.2006e-03, -2.3713e-03, -2.4520e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7986e-03, -1.9039e-03, -1.9271e-03],\n",
      "          [-1.9800e-03, -2.1132e-03, -2.1557e-03],\n",
      "          [-2.0692e-03, -2.2204e-03, -2.2789e-03]],\n",
      "\n",
      "         [[ 3.0164e-04,  3.5218e-04,  3.8540e-04],\n",
      "          [ 4.7675e-04,  5.5563e-04,  6.1021e-04],\n",
      "          [ 6.3053e-04,  7.2717e-04,  7.9350e-04]],\n",
      "\n",
      "         [[ 6.0064e-05,  2.3722e-05, -1.5551e-05],\n",
      "          [ 1.6174e-04,  1.0854e-04,  4.9992e-05],\n",
      "          [ 2.6219e-04,  1.9264e-04,  1.1536e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7300e-04,  7.6541e-04,  7.2099e-04],\n",
      "          [ 7.5696e-04,  7.4898e-04,  7.0571e-04],\n",
      "          [ 6.9560e-04,  6.8715e-04,  6.4702e-04]],\n",
      "\n",
      "         [[ 3.3164e-04,  3.1837e-04,  2.9471e-04],\n",
      "          [ 3.3186e-04,  3.1641e-04,  2.9060e-04],\n",
      "          [ 3.1551e-04,  2.9951e-04,  2.7351e-04]],\n",
      "\n",
      "         [[ 1.6734e-03,  1.7023e-03,  1.6373e-03],\n",
      "          [ 1.6676e-03,  1.7061e-03,  1.6460e-03],\n",
      "          [ 1.5753e-03,  1.6221e-03,  1.5712e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8388e-04,  2.6557e-04,  1.4190e-04],\n",
      "          [ 3.7175e-04,  2.4937e-04,  1.2372e-04],\n",
      "          [ 3.3537e-04,  2.1771e-04,  9.8208e-05]],\n",
      "\n",
      "         [[-6.3633e-04, -6.6729e-04, -6.7937e-04],\n",
      "          [-6.7601e-04, -7.1297e-04, -7.2799e-04],\n",
      "          [-6.8692e-04, -7.2686e-04, -7.4233e-04]],\n",
      "\n",
      "         [[-5.3952e-05, -4.6290e-05, -4.0857e-05],\n",
      "          [-6.3421e-05, -4.9680e-05, -3.9629e-05],\n",
      "          [-6.6957e-05, -4.7532e-05, -3.3068e-05]]]])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('data/goldfish.jpg')[..., ::-1]\n",
    "img_np = np.array(img)\n",
    "_, dip(img_np, arch = 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = ['it_0.png', 'it_100.png']\n",
    "image_dataset.append(['it_{}.png'.format(100*i) for i in range(60, 101)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'it_' + 100*i + '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img = cv2.imread('data/knife.jpg')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
